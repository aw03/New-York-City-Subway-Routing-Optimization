{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "42a3820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, Gurobi, CSV, DataFrames, Statistics, Distances, JuMP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe509ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRecursively scanning directory: .\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\MTA_Subway_Hourly_Ridership__Oct_21_2024_Evening.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\MTA_Subway_Hourly_Ridership__Oct_21_2024_Morning.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\MTA_Subway_Stations_20251204.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\agency.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\calendar.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\calendar_dates.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\linecapacity.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\linelength.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\routes.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\shapes.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\stop_times.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Summary ---\n",
      "Dataset: 'routes'\n",
      "  Shape: 29 rows × 10 columns\n",
      "  Cols:  route_id, agency_id, route_short_name, route_long_name, route_desc, route_type, route_url, route_color, route_text_color, route_sort_order\n",
      "--------------------\n",
      "Dataset: 'nodes_with_ridership'\n",
      "  Shape: 475 rows × 9 columns\n",
      "  Cols:  node_idx, stop_id, stop_name, stop_lon, stop_lat, station_complex_id, ridership_morning, ridership_evening, net_ridership\n",
      "--------------------\n",
      "Dataset: 'stops'\n",
      "  Shape: 1488 rows × 6 columns\n",
      "  Cols:  stop_id, stop_name, stop_lat, stop_lon, location_type, parent_station\n",
      "--------------------\n",
      "Dataset: 'trips'\n",
      "  Shape: 20304 rows × 6 columns\n",
      "  Cols:  route_id, trip_id, service_id, trip_headsign, direction_id, shape_id\n",
      "--------------------\n",
      "Dataset: 'MTA_Subway_Aggregated_Ridership_Oct_21_2024_Evening'\n",
      "  Shape: 424 rows × 2 columns\n",
      "  Cols:  station_complex_id, ridership\n",
      "--------------------\n",
      "Dataset: 'agency'\n",
      "  Shape: 1 rows × 6 columns\n",
      "  Cols:  agency_id, agency_name, agency_url, agency_timezone, agency_lang, agency_phone\n",
      "--------------------\n",
      "Dataset: 'nodes_with_balanced_integer_net_ridership'\n",
      "  Shape: 475 rows × 11 columns\n",
      "  Cols:  node_idx, stop_id, stop_name, stop_lon, stop_lat, station_complex_id, ridership_morning, ridership_evening, net_ridership, balanced_real, balanced_net_ridership_int\n",
      "--------------------\n",
      "Dataset: 'stop_times'\n",
      "  Shape: 562597 rows × 5 columns\n",
      "  Cols:  trip_id, stop_id, arrival_time, departure_time, stop_sequence\n",
      "--------------------\n",
      "Dataset: 'MTA_Subway_Hourly_Ridership__Oct_21_2024_Morning'\n",
      "  Shape: 15549 rows × 12 columns\n",
      "  Cols:  transit_timestamp, transit_mode, station_complex_id, station_complex, borough, payment_method, fare_class_category, ridership, transfers, latitude, longitude, Georeference\n",
      "--------------------\n",
      "Dataset: 'stop_routes'\n",
      "  Shape: 475 rows × 3 columns\n",
      "  Cols:  stop_id, stop_name, routes_at_stop\n",
      "--------------------\n",
      "Dataset: 'MTA_Subway_Aggregated_Ridership_Oct_21_2024_Morning'\n",
      "  Shape: 424 rows × 2 columns\n",
      "  Cols:  station_complex_id, ridership\n",
      "--------------------\n",
      "Dataset: 'shapes'\n",
      "  Shape: 149834 rows × 4 columns\n",
      "  Cols:  shape_id, shape_pt_sequence, shape_pt_lat, shape_pt_lon\n",
      "--------------------\n",
      "Dataset: 'edges_by_route'\n",
      "  Shape: 1039 rows × 8 columns\n",
      "  Cols:  edge_idx, from_idx, to_idx, route_idx, from_stop_id, to_stop_id, route_short_name, count\n",
      "--------------------\n",
      "Dataset: 'calendar'\n",
      "  Shape: 3 rows × 10 columns\n",
      "  Cols:  service_id, monday, tuesday, wednesday, thursday, friday, saturday, sunday, start_date, end_date\n",
      "--------------------\n",
      "Dataset: 'evening_4to8_with_gtfs'\n",
      "  Shape: 475 rows × 3 columns\n",
      "  Cols:  station_complex_id, ridership, GTFS Stop ID\n",
      "--------------------\n",
      "Dataset: 'calendar_dates'\n",
      "  Shape: 8 rows × 3 columns\n",
      "  Cols:  service_id, date, exception_type\n",
      "--------------------\n",
      "Dataset: 'nodes'\n",
      "  Shape: 475 rows × 5 columns\n",
      "  Cols:  node_idx, stop_id, stop_name, stop_lon, stop_lat\n",
      "--------------------\n",
      "Dataset: 'nodes_with_balanced_net_ridership'\n",
      "  Shape: 475 rows × 10 columns\n",
      "  Cols:  node_idx, stop_id, stop_name, stop_lon, stop_lat, station_complex_id, ridership_morning, ridership_evening, net_ridership, balanced_net_ridership\n",
      "--------------------\n",
      "Dataset: 'generated_graphs_routes'\n",
      "  Shape: 26 rows × 2 columns\n",
      "  Cols:  route_idx, route_short_name\n",
      "--------------------\n",
      "Dataset: 'linelength'\n",
      "  Shape: 26 rows × 4 columns\n",
      "  Cols:  route_idx, route_short_name, route_length(mi), route_stations(rush_hour)\n",
      "--------------------\n",
      "Dataset: 'morning_6to10_with_gtfs'\n",
      "  Shape: 475 rows × 3 columns\n",
      "  Cols:  station_complex_id, ridership, GTFS Stop ID\n",
      "--------------------\n",
      "Dataset: 'MTA_Subway_Hourly_Ridership__Oct_21_2024_Evening'\n",
      "  Shape: 15311 rows × 12 columns\n",
      "  Cols:  transit_timestamp, transit_mode, station_complex_id, station_complex, borough, payment_method, fare_class_category, ridership, transfers, latitude, longitude, Georeference\n",
      "--------------------\n",
      "Dataset: 'MTA_Subway_Stations_20251204'\n",
      "  Shape: 496 rows × 19 columns\n",
      "  Cols:  GTFS Stop ID, Station ID, Complex ID, Division, Line, Stop Name, Borough, CBD, Daytime Routes, Structure, GTFS Latitude, GTFS Longitude, North Direction Label, South Direction Label, ADA, ADA Northbound, ADA Southbound, ADA Notes, Georeference\n",
      "--------------------\n",
      "Dataset: 'linecapacity'\n",
      "  Shape: 26 rows × 5 columns\n",
      "  Cols:  route_idx, route_short_name, cars_per_train, rush_hour_capacity_per_car, total_rush_hour_capacity\n",
      "--------------------\n",
      "Dataset: 'transfer_edges'\n",
      "  Shape: 150 rows × 8 columns\n",
      "  Cols:  transfer_edge_id, from_stop_id, to_stop_id, from_idx, to_idx, transfer_type, min_transfer_time, cost\n",
      "--------------------\n",
      "Dataset: 'transfers'\n",
      "  Shape: 613 rows × 4 columns\n",
      "  Cols:  from_stop_id, to_stop_id, transfer_type, min_transfer_time\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\stops.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\transfers.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\trips.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\edges_by_route.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\nodes.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\nodes_with_balanced_integer_net_ridership.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\nodes_with_balanced_net_ridership.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\nodes_with_ridership.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\routes.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\stop_routes.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\transfer_edges.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_turnstile_data\\MTA_Subway_Aggregated_Ridership_Oct_21_2024_Evening.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_turnstile_data\\MTA_Subway_Aggregated_Ridership_Oct_21_2024_Morning.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_turnstile_data\\evening_4to8_with_gtfs.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_turnstile_data\\morning_6to10_with_gtfs.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSuccessfully loaded 26 datasets.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    load_repo_data(repo_path::String)\n",
    "\n",
    "Recursively walks through the specified repository path, identifies all `.csv` and `.txt` files\n",
    "(even in subfolders), and parses them into a Dictionary of DataFrames.\n",
    "\n",
    "# Arguments\n",
    "- `repo_path::String`: The local path to the cloned repository.\n",
    "\n",
    "# Returns\n",
    "- `Dict{String, DataFrame}`: A dictionary where keys are unique filenames and values are DataFrames.\n",
    "\"\"\"\n",
    "function load_repo_data(repo_path::String)\n",
    "    # Dictionary to store the parsed data\n",
    "    data_store = Dict{String, DataFrame}()\n",
    "    \n",
    "    # CSV options (assume headers exist)\n",
    "    csv_options = (header=true, stringtype=String)\n",
    "\n",
    "    if !isdir(repo_path)\n",
    "        @error \"Directory not found: $repo_path\"\n",
    "        return data_store\n",
    "    end\n",
    "\n",
    "    @info \"Recursively scanning directory: $repo_path\"\n",
    "    \n",
    "    files_found = 0\n",
    "    \n",
    "    # walkdir allows us to search subdirectories (e.g., /data, /src)\n",
    "    for (root, dirs, files) in walkdir(repo_path)\n",
    "        for file in files\n",
    "            # Check for valid extensions\n",
    "            if endswith(lowercase(file), \".csv\") || endswith(lowercase(file), \".txt\")\n",
    "                \n",
    "                files_found += 1\n",
    "                full_path = joinpath(root, file)\n",
    "                dataset_name = splitext(file)[1]\n",
    "                \n",
    "                # Handle duplicate filenames in different folders by appending parent folder name\n",
    "                if haskey(data_store, dataset_name)\n",
    "                    parent_folder = basename(root)\n",
    "                    dataset_name = \"$(parent_folder)_$(dataset_name)\"\n",
    "                end\n",
    "\n",
    "                try\n",
    "                    @info \"Parsing: $full_path\"\n",
    "                    df = CSV.read(full_path, DataFrame; csv_options...)\n",
    "                    data_store[dataset_name] = df\n",
    "                catch e\n",
    "                    # Only warn, don't crash, if a file is malformed\n",
    "                    @warn \"Skipping $file: Unable to parse as CSV table.\"\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if files_found == 0\n",
    "        @warn \"No CSV or TXT files were found in $repo_path or its subdirectories.\"\n",
    "        @info \"Current working directory contains: $(readdir(repo_path))\"\n",
    "    else\n",
    "        @info \"Successfully loaded $(length(data_store)) datasets.\"\n",
    "    end\n",
    "\n",
    "    return data_store\n",
    "end\n",
    "\"\"\"\n",
    "    summarize_data(data::Dict{String, DataFrame})\n",
    "\n",
    "Prints a brief summary of the loaded datasets.\n",
    "\"\"\"\n",
    "function summarize_data(data::Dict{String, DataFrame})\n",
    "    println(\"\\n--- Data Summary ---\")\n",
    "    for (name, df) in data\n",
    "        println(\"Dataset: '$name'\")\n",
    "        println(\"  Shape: $(nrow(df)) rows × $(ncol(df)) columns\")\n",
    "        println(\"  Cols:  $(join(names(df), \", \"))\")\n",
    "        println(\"--------------------\")\n",
    "    end\n",
    "end\n",
    "\n",
    "repo_path = \".\" \n",
    "\n",
    "# 2. Load the data\n",
    "\n",
    "subway_data = load_repo_data(repo_path)\n",
    "\n",
    "# 3. Print summary\n",
    "summarize_data(subway_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eff59c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "build_subway_model (generic function with 1 method)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    build_subway_model(V, E_track, E_transfer, L, L_ij; kwargs...) -> model\n",
    "\n",
    "Builds the Gurobi/JuMP model for the subway optimization problem with:\n",
    "- track edges E_track\n",
    "- transfer edges E_transfer\n",
    "- line set L\n",
    "- per-edge line sets L_ij\n",
    "\n",
    "This ONLY builds the optimizer; it does not read any CSVs.\n",
    "You must construct the sets and parameter dictionaries before calling it.\n",
    "\n",
    "Arguments\n",
    "---------\n",
    "V::Vector{Station}                # stations (any index type: Int, String, etc.)\n",
    "E_track::Vector{Tuple{Station,Station}}\n",
    "E_transfer::Vector{Tuple{Station,Station}}\n",
    "L::Vector{Line}\n",
    "L_ij::Dict{Tuple{Station,Station},Vector{Line}}\n",
    "\n",
    "Keyword parameters (all REQUIRED)\n",
    "---------------------------------\n",
    "s::Dict{Station,Float64}                             # s_i\n",
    "t::Dict{Tuple{Station,Station,Line},Float64}         # t_{ijℓ}\n",
    "t_tr::Dict{Tuple{Station,Station},Float64}           # t^{tr}_{ij}\n",
    "C_train::Float64                                     # C_train\n",
    "Δ::Float64                                           # Δ\n",
    "τ::Dict{Line,Float64}                                # τ_ℓ\n",
    "energy::Dict{Line,Float64}                           # energy_ℓ\n",
    "T_max::Float64                                       # T_max\n",
    "β::Float64                                           # β\n",
    "γ::Float64                                           # γ\n",
    "λ::Float64                                           # λ ∈ [0,1]\n",
    "\n",
    "Optional\n",
    "--------\n",
    "shared_track_constraint::Bool = true\n",
    "\n",
    "Returns\n",
    "-------\n",
    "::JuMP.Model (with Gurobi as optimizer)\n",
    "\"\"\"\n",
    "\n",
    "function build_subway_model(\n",
    "    V,\n",
    "    E_track,\n",
    "    E_transfer,\n",
    "    L,\n",
    "    L_ij;\n",
    "    s,\n",
    "    t,\n",
    "    t_tr,\n",
    "    C_train,   # Dict{Line,Float64}\n",
    "    Δ,\n",
    "    τ,\n",
    "    energy,\n",
    "    T_max,\n",
    "    β,\n",
    "    γ,\n",
    "    λ,\n",
    "    shared_track_constraint::Bool = true,\n",
    ")\n",
    "\n",
    "    model = Model(Gurobi.Optimizer)\n",
    "\n",
    "    # -------------------------\n",
    "    # 1. Symmetrize the Network\n",
    "    # -------------------------\n",
    "    # We build a set of triplets that allows flow in BOTH directions \n",
    "    # for every physical connection provided.\n",
    "    \n",
    "    triplet_set = Set{Tuple{eltype(V),eltype(V),eltype(L)}}()\n",
    "    \n",
    "    # Helper to register a directed edge (i->j) and its reverse (j->i)\n",
    "    function register_edge(i, j, lines)\n",
    "        for ℓ in lines\n",
    "            push!(triplet_set, (i, j, ℓ))\n",
    "            push!(triplet_set, (j, i, ℓ))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Process all input track edges\n",
    "    for (i, j) in E_track\n",
    "        lines = get(L_ij, (i, j), Vector{eltype(L)}())\n",
    "        register_edge(i, j, lines)\n",
    "    end\n",
    "\n",
    "    track_triplets = collect(triplet_set)\n",
    "    \n",
    "    # Identify unique edges (directional) for iterating constraints\n",
    "    # (Group by i, j)\n",
    "    segments = Set{Tuple{eltype(V), eltype(V)}}()\n",
    "    for (i, j, ℓ) in track_triplets\n",
    "        push!(segments, (i, j))\n",
    "    end\n",
    "\n",
    "    # -------------------------\n",
    "    # Variables\n",
    "    # -------------------------\n",
    "    @variable(model, x[track_triplets] >= 0)\n",
    "    @variable(model, y[E_transfer] >= 0)\n",
    "    @variable(model, f[L] >= 0)\n",
    "    @variable(model, overflow[track_triplets] >= 0)\n",
    "\n",
    "    # -------------------------\n",
    "    # (1) Flow Conservation\n",
    "    # -------------------------\n",
    "    for i in V\n",
    "        # Flow leaving i via track\n",
    "        out_track = sum(\n",
    "            x[(i, j, ℓ)] \n",
    "            for (start_node, j, ℓ) in track_triplets \n",
    "            if start_node == i;\n",
    "            init = 0.0\n",
    "        )\n",
    "\n",
    "        # Flow leaving i via transfer\n",
    "        out_transfer = sum(\n",
    "            y[(i, j)] \n",
    "            for (start_node, j) in E_transfer \n",
    "            if start_node == i;\n",
    "            init = 0.0\n",
    "        )\n",
    "\n",
    "        # Flow entering i via track\n",
    "        in_track = sum(\n",
    "            x[(k, i, ℓ)] \n",
    "            for (k, end_node, ℓ) in track_triplets \n",
    "            if end_node == i;\n",
    "            init = 0.0\n",
    "        )\n",
    "\n",
    "        # Flow entering i via transfer\n",
    "        in_transfer = sum(\n",
    "            y[(k, i)] \n",
    "            for (k, end_node) in E_transfer \n",
    "            if end_node == i;\n",
    "            init = 0.0\n",
    "        )\n",
    "\n",
    "        @constraint(model, out_track + out_transfer - in_track - in_transfer == s[i])\n",
    "    end\n",
    "\n",
    "    # -------------------------\n",
    "    # (2) Capacity\n",
    "    # -------------------------\n",
    "    for (i, j, ℓ) in track_triplets\n",
    "        # Note: We assume C_train is per-line. \n",
    "        # Since we use C_train[ℓ], it applies correctly to both directions.\n",
    "        @constraint(model, x[(i, j, ℓ)] - overflow[(i, j, ℓ)] <= C_train[ℓ] * f[ℓ] * Δ)\n",
    "    end\n",
    "\n",
    "    # -------------------------\n",
    "    # (3) Shared Track\n",
    "    # -------------------------\n",
    "    # We iterate over our discovered segments, not the raw input E_track\n",
    "    if shared_track_constraint\n",
    "        for (i, j) in segments\n",
    "            # Find all lines serving this specific directed segment\n",
    "            # (We filter the triplets manually or could pre-build a dict)\n",
    "            lines_on_segment = [l for (u, v, l) in track_triplets if u == i && v == j]\n",
    "            \n",
    "            if !isempty(lines_on_segment)\n",
    "                lhs = sum(x[(i, j, ℓ)] - overflow[(i, j, ℓ)] for ℓ in lines_on_segment)\n",
    "                rhs = sum(C_train[ℓ] * f[ℓ] * Δ for ℓ in lines_on_segment)\n",
    "                @constraint(model, lhs <= rhs)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # -------------------------\n",
    "    # (4) Fleet/Energy Limit\n",
    "    # -------------------------\n",
    "    @constraint(model, sum(f[ℓ] * τ[ℓ] for ℓ in L; init=0.0) <= T_max)\n",
    "\n",
    "    # -------------------------\n",
    "    # Objective\n",
    "    # -------------------------\n",
    "    \n",
    "    # Helper to find cost t for (i, j, ℓ) safely\n",
    "    # If t[(i, j, ℓ)] missing, try t[(j, i, ℓ)]\n",
    "    function get_cost(i, j, ℓ)\n",
    "        if haskey(t, (i, j, ℓ))\n",
    "            return t[(i, j, ℓ)]\n",
    "        elseif haskey(t, (j, i, ℓ))\n",
    "            return t[(j, i, ℓ)]\n",
    "        else\n",
    "            return 1.0 # Default fallback\n",
    "        end\n",
    "    end\n",
    "\n",
    "    passenger_time_expr =\n",
    "        sum(get_cost(i, j, ℓ) * x[(i, j, ℓ)] for (i, j, ℓ) in track_triplets; init=0.0) +\n",
    "        sum(t_tr[(i, j)] * y[(i, j)] for (i, j) in E_transfer; init=0.0)\n",
    "\n",
    "    overflow_expr = β * sum(overflow[triplet] for triplet in track_triplets; init=0.0)\n",
    "\n",
    "    energy_expr = γ * sum(energy[ℓ] * f[ℓ] for ℓ in L; init=0.0)\n",
    "\n",
    "    @objective(model, Min,\n",
    "        (1 - λ) * (passenger_time_expr + overflow_expr) +\n",
    "        λ * energy_expr\n",
    "    )\n",
    "\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af0da5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>150×8 DataFrame</span></div><div style = \"float: right; font-style: italic;\"><span>125 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"columnLabelRow\"><th class = \"stubheadLabel\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">transfer_edge_id</th><th style = \"text-align: left;\">from_stop_id</th><th style = \"text-align: left;\">to_stop_id</th><th style = \"text-align: left;\">from_idx</th><th style = \"text-align: left;\">to_idx</th><th style = \"text-align: left;\">transfer_type</th><th style = \"text-align: left;\">min_transfer_time</th><th style = \"text-align: left;\">cost</th></tr><tr class = \"columnLabelRow\"><th class = \"stubheadLabel\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String3\" style = \"text-align: left;\">String3</th><th title = \"String3\" style = \"text-align: left;\">String3</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">112</td><td style = \"text-align: left;\">A09</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">183</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">125</td><td style = \"text-align: left;\">A24</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">196</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">127</td><td style = \"text-align: left;\">725</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">174</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">3</td><td style = \"text-align: left;\">127</td><td style = \"text-align: left;\">902</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">177</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">4</td><td style = \"text-align: left;\">127</td><td style = \"text-align: left;\">A27</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">198</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">300</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">5</td><td style = \"text-align: left;\">127</td><td style = \"text-align: left;\">R16</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">444</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">6</td><td style = \"text-align: left;\">132</td><td style = \"text-align: left;\">D19</td><td style = \"text-align: right;\">29</td><td style = \"text-align: right;\">263</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">300</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">7</td><td style = \"text-align: left;\">132</td><td style = \"text-align: left;\">L02</td><td style = \"text-align: right;\">29</td><td style = \"text-align: right;\">379</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">8</td><td style = \"text-align: left;\">222</td><td style = \"text-align: left;\">415</td><td style = \"text-align: right;\">57</td><td style = \"text-align: right;\">105</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">9</td><td style = \"text-align: left;\">228</td><td style = \"text-align: left;\">A36</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">205</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">10</td><td style = \"text-align: left;\">228</td><td style = \"text-align: left;\">E01</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">286</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">11</td><td style = \"text-align: left;\">228</td><td style = \"text-align: left;\">R25</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">453</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">420</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">12</td><td style = \"text-align: left;\">229</td><td style = \"text-align: left;\">418</td><td style = \"text-align: right;\">63</td><td style = \"text-align: right;\">107</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">300</td><td style = \"text-align: right;\">1</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: left;\">&vellip;</td><td style = \"text-align: left;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">139</td><td style = \"text-align: right;\">138</td><td style = \"text-align: left;\">R23</td><td style = \"text-align: left;\">Q01</td><td style = \"text-align: right;\">451</td><td style = \"text-align: right;\">429</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">140</td><td style = \"text-align: right;\">139</td><td style = \"text-align: left;\">R25</td><td style = \"text-align: left;\">E01</td><td style = \"text-align: right;\">453</td><td style = \"text-align: right;\">286</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">240</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">141</td><td style = \"text-align: right;\">140</td><td style = \"text-align: left;\">R25</td><td style = \"text-align: left;\">A36</td><td style = \"text-align: right;\">453</td><td style = \"text-align: right;\">205</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">420</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">142</td><td style = \"text-align: right;\">141</td><td style = \"text-align: left;\">R25</td><td style = \"text-align: left;\">228</td><td style = \"text-align: right;\">453</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">420</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">143</td><td style = \"text-align: right;\">142</td><td style = \"text-align: left;\">R28</td><td style = \"text-align: left;\">232</td><td style = \"text-align: right;\">456</td><td style = \"text-align: right;\">66</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">144</td><td style = \"text-align: right;\">143</td><td style = \"text-align: left;\">R28</td><td style = \"text-align: left;\">423</td><td style = \"text-align: right;\">456</td><td style = \"text-align: right;\">110</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">145</td><td style = \"text-align: right;\">144</td><td style = \"text-align: left;\">R29</td><td style = \"text-align: left;\">A41</td><td style = \"text-align: right;\">457</td><td style = \"text-align: right;\">208</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">90</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">146</td><td style = \"text-align: right;\">145</td><td style = \"text-align: left;\">R31</td><td style = \"text-align: left;\">235</td><td style = \"text-align: right;\">459</td><td style = \"text-align: right;\">69</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">147</td><td style = \"text-align: right;\">146</td><td style = \"text-align: left;\">R31</td><td style = \"text-align: left;\">D24</td><td style = \"text-align: right;\">459</td><td style = \"text-align: right;\">267</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">300</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">148</td><td style = \"text-align: right;\">147</td><td style = \"text-align: left;\">R33</td><td style = \"text-align: left;\">F23</td><td style = \"text-align: right;\">461</td><td style = \"text-align: right;\">304</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">149</td><td style = \"text-align: right;\">148</td><td style = \"text-align: left;\">S01</td><td style = \"text-align: left;\">A45</td><td style = \"text-align: right;\">472</td><td style = \"text-align: right;\">212</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">150</td><td style = \"text-align: right;\">149</td><td style = \"text-align: left;\">S04</td><td style = \"text-align: left;\">239</td><td style = \"text-align: right;\">474</td><td style = \"text-align: right;\">73</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& transfer\\_edge\\_id & from\\_stop\\_id & to\\_stop\\_id & from\\_idx & to\\_idx & transfer\\_type & min\\_transfer\\_time & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String3 & String3 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0 & 112 & A09 & 9 & 183 & 2 & 180 & $\\dots$ \\\\\n",
       "\t2 & 1 & 125 & A24 & 22 & 196 & 2 & 180 & $\\dots$ \\\\\n",
       "\t3 & 2 & 127 & 725 & 24 & 174 & 2 & 180 & $\\dots$ \\\\\n",
       "\t4 & 3 & 127 & 902 & 24 & 177 & 2 & 180 & $\\dots$ \\\\\n",
       "\t5 & 4 & 127 & A27 & 24 & 198 & 2 & 300 & $\\dots$ \\\\\n",
       "\t6 & 5 & 127 & R16 & 24 & 444 & 2 & 180 & $\\dots$ \\\\\n",
       "\t7 & 6 & 132 & D19 & 29 & 263 & 2 & 300 & $\\dots$ \\\\\n",
       "\t8 & 7 & 132 & L02 & 29 & 379 & 2 & 180 & $\\dots$ \\\\\n",
       "\t9 & 8 & 222 & 415 & 57 & 105 & 2 & 180 & $\\dots$ \\\\\n",
       "\t10 & 9 & 228 & A36 & 62 & 205 & 2 & 180 & $\\dots$ \\\\\n",
       "\t11 & 10 & 228 & E01 & 62 & 286 & 2 & 180 & $\\dots$ \\\\\n",
       "\t12 & 11 & 228 & R25 & 62 & 453 & 2 & 420 & $\\dots$ \\\\\n",
       "\t13 & 12 & 229 & 418 & 63 & 107 & 2 & 300 & $\\dots$ \\\\\n",
       "\t14 & 13 & 229 & A38 & 63 & 206 & 2 & 180 & $\\dots$ \\\\\n",
       "\t15 & 14 & 229 & M22 & 63 & 418 & 2 & 300 & $\\dots$ \\\\\n",
       "\t16 & 15 & 232 & 423 & 66 & 110 & 2 & 300 & $\\dots$ \\\\\n",
       "\t17 & 16 & 232 & R28 & 66 & 456 & 2 & 180 & $\\dots$ \\\\\n",
       "\t18 & 17 & 235 & D24 & 69 & 267 & 2 & 180 & $\\dots$ \\\\\n",
       "\t19 & 18 & 235 & R31 & 69 & 459 & 2 & 180 & $\\dots$ \\\\\n",
       "\t20 & 19 & 239 & S04 & 73 & 474 & 2 & 180 & $\\dots$ \\\\\n",
       "\t21 & 20 & 254 & L26 & 87 & 398 & 2 & 300 & $\\dots$ \\\\\n",
       "\t22 & 21 & 414 & D11 & 104 & 255 & 2 & 180 & $\\dots$ \\\\\n",
       "\t23 & 22 & 415 & 222 & 105 & 57 & 2 & 180 & $\\dots$ \\\\\n",
       "\t24 & 23 & 418 & 229 & 107 & 63 & 2 & 300 & $\\dots$ \\\\\n",
       "\t25 & 24 & 418 & A38 & 107 & 206 & 2 & 180 & $\\dots$ \\\\\n",
       "\t26 & 25 & 418 & M22 & 107 & 418 & 2 & 300 & $\\dots$ \\\\\n",
       "\t27 & 26 & 423 & 232 & 110 & 66 & 2 & 300 & $\\dots$ \\\\\n",
       "\t28 & 27 & 423 & R28 & 110 & 456 & 2 & 180 & $\\dots$ \\\\\n",
       "\t29 & 28 & 629 & B08 & 142 & 232 & 2 & 300 & $\\dots$ \\\\\n",
       "\t30 & 29 & 629 & R11 & 142 & 440 & 2 & 180 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m150×8 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m transfer_edge_id \u001b[0m\u001b[1m from_stop_id \u001b[0m\u001b[1m to_stop_id \u001b[0m\u001b[1m from_idx \u001b[0m\u001b[1m to_idx \u001b[0m\u001b[1m transfer_\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64            \u001b[0m\u001b[90m String3      \u001b[0m\u001b[90m String3    \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Int64    \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │                0  112           A09                9     183            ⋯\n",
       "   2 │                1  125           A24               22     196\n",
       "   3 │                2  127           725               24     174\n",
       "   4 │                3  127           902               24     177\n",
       "   5 │                4  127           A27               24     198            ⋯\n",
       "   6 │                5  127           R16               24     444\n",
       "   7 │                6  132           D19               29     263\n",
       "   8 │                7  132           L02               29     379\n",
       "   9 │                8  222           415               57     105            ⋯\n",
       "  10 │                9  228           A36               62     205\n",
       "  11 │               10  228           E01               62     286\n",
       "  ⋮  │        ⋮               ⋮            ⋮          ⋮        ⋮           ⋮   ⋱\n",
       " 141 │              140  R25           A36              453     205\n",
       " 142 │              141  R25           228              453      62            ⋯\n",
       " 143 │              142  R28           232              456      66\n",
       " 144 │              143  R28           423              456     110\n",
       " 145 │              144  R29           A41              457     208\n",
       " 146 │              145  R31           235              459      69            ⋯\n",
       " 147 │              146  R31           D24              459     267\n",
       " 148 │              147  R33           F23              461     304\n",
       " 149 │              148  S01           A45              472     212\n",
       " 150 │              149  S04           239              474      73            ⋯\n",
       "\u001b[36m                                                  3 columns and 129 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "nodes_df      = CSV.read(\"generated_graphs\\\\nodes_with_balanced_integer_net_ridership.csv\", DataFrame)\n",
    "routes_df     = CSV.read(\"generated_graphs\\\\routes.csv\", DataFrame)\n",
    "edges_df      = CSV.read(\"generated_graphs\\\\edges_by_route.csv\", DataFrame)\n",
    "transfers_df  = CSV.read(\"generated_graphs\\\\transfer_edges.csv\", DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3496e20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const Station = Int\n",
    "const Line    = Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e3987b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(475,)\n",
      "(26,)\n"
     ]
    }
   ],
   "source": [
    "V = sort(unique(Station.(nodes_df.node_idx)))      # stations\n",
    "L = sort(unique(Line.(routes_df.route_idx)))       # lines\n",
    "println(size(V))\n",
    "println(size(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "624ab6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556,)"
     ]
    }
   ],
   "source": [
    "E_track = unique([(Station(row.from_idx), Station(row.to_idx)) \n",
    "                  for row in eachrow(edges_df)])\n",
    "print(size(E_track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e2db7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Tuple{Int64, Int64}, Vector{Int64}} with 556 entries:\n",
       "  (126, 127) => [5]\n",
       "  (359, 360) => [9, 23]\n",
       "  (55, 56)   => [1, 4]\n",
       "  (117, 118) => [5, 6]\n",
       "  (213, 214) => [9, 11]\n",
       "  (7, 8)     => [0]\n",
       "  (223, 224) => [9]\n",
       "  (14, 15)   => [0]\n",
       "  (397, 398) => [18]\n",
       "  (433, 434) => [20, 24]\n",
       "  (178, 179) => [9]\n",
       "  (267, 268) => [10, 21]\n",
       "  (368, 370) => [17]\n",
       "  (121, 122) => [5, 6]\n",
       "  (436, 437) => [20, 24]\n",
       "  (473, 474) => [23]\n",
       "  (151, 152) => [3, 5, 6]\n",
       "  (26, 27)   => [0, 1]\n",
       "  (154, 155) => [7, 8]\n",
       "  (308, 309) => [14, 15]\n",
       "  (336, 337) => [16]\n",
       "  (171, 172) => [7, 8]\n",
       "  (345, 346) => [16]\n",
       "  (261, 262) => [14, 15, 19]\n",
       "  (444, 445) => [20, 24, 21, 22]\n",
       "  ⋮          => ⋮"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_ij = Dict{Tuple{Station,Station}, Vector{Line}}()\n",
    "\n",
    "for row in eachrow(edges_df)\n",
    "    i = Station(row.from_idx)\n",
    "    j = Station(row.to_idx)\n",
    "    ℓ = Line(row.route_idx)\n",
    "    key = (i, j)\n",
    "    if haskey(L_ij, key)\n",
    "        push!(L_ij[key], ℓ)\n",
    "    else\n",
    "        L_ij[key] = [ℓ]\n",
    "    end\n",
    "end\n",
    "\n",
    "# Remove duplicates within each vector, in case the same route appears multiple times\n",
    "for lines in values(L_ij)\n",
    "    unique!(lines)\n",
    "end\n",
    "L_ij\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bcc87ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "E_transfer = unique([(Station(row.from_idx), Station(row.to_idx))\n",
    "                     for row in eachrow(transfers_df)])\n",
    "println(size(E_transfer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dc190808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Tuple{Int64, Int64}, Float64} with 150 entries:\n",
       "  (416, 429) => 1.0\n",
       "  (63, 418)  => 1.0\n",
       "  (472, 212) => 1.0\n",
       "  (429, 152) => 1.0\n",
       "  (172, 144) => 1.0\n",
       "  (24, 177)  => 1.0\n",
       "  (212, 472) => 1.0\n",
       "  (416, 451) => 1.0\n",
       "  (198, 174) => 1.0\n",
       "  (453, 205) => 1.0\n",
       "  (453, 62)  => 1.0\n",
       "  (429, 451) => 1.0\n",
       "  (29, 263)  => 1.0\n",
       "  (335, 294) => 1.0\n",
       "  (456, 66)  => 1.0\n",
       "  (177, 444) => 1.0\n",
       "  (422, 238) => 1.0\n",
       "  (169, 335) => 1.0\n",
       "  (198, 177) => 1.0\n",
       "  (173, 260) => 1.0\n",
       "  (176, 172) => 1.0\n",
       "  (73, 474)  => 1.0\n",
       "  (107, 63)  => 1.0\n",
       "  (379, 263) => 1.0\n",
       "  (148, 448) => 1.0\n",
       "  ⋮          => ⋮"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_tr = Dict((i, j) => 1.0 for (i, j) in E_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b316e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Dict{Tuple{Station,Station,Line}, Float64}()\n",
    "\n",
    "for row in eachrow(edges_df)\n",
    "    i = Station(row.from_idx)\n",
    "    j = Station(row.to_idx)\n",
    "    ℓ = Line(row.route_idx)\n",
    "    key = (i, j, ℓ)\n",
    "    \n",
    "    # If every segment has the same unit cost:\n",
    "    t[key] = 1.0\n",
    "\n",
    "    # Later you can replace that with actual in-train travel time per edge\n",
    "    # t[key] = real_travel_time_in_hours\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5bc1ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Dict{Station, Float64}()\n",
    "\n",
    "for row in eachrow(nodes_df)\n",
    "    i = Station(row.node_idx)\n",
    "    s[i] = Float64(row.balanced_net_ridership_int)\n",
    "end\n",
    "\n",
    "# Optionally, ensure every station in V has an entry, even if 0:\n",
    "for i in V\n",
    "    if !haskey(s, i)\n",
    "        s[i] = 0.0\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "86466c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Line = Int  # same as you used elsewhere\n",
    "\n",
    "linecap_df = CSV.read(\"datasets\\\\linecapacity.csv\", DataFrame)\n",
    "\n",
    "C_train = Dict{Line, Float64}()\n",
    "\n",
    "for row in eachrow(linecap_df)\n",
    "    ℓ = Line(row.route_idx)  # line index used in the model\n",
    "    # capacity per train on that line:\n",
    "    C_train[ℓ] = Float64(row.total_rush_hour_capacity)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad6b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2703606\n",
      "Academic license 2703606 - for non-commercial use only - registered to ju___@mit.edu\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i9-14900K, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 24 physical cores, 32 logical processors, using up to 32 threads\n",
      "\n",
      "Academic license 2703606 - for non-commercial use only - registered to ju___@mit.edu\n",
      "Optimize a model with 3666 rows, 4332 columns and 16950 nonzeros\n",
      "Model fingerprint: 0x67aa95af\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+05]\n",
      "  Objective range  [1e-03, 5e+02]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+01, 4e+04]\n",
      "Presolve removed 533 rows and 96 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 3133 rows, 4236 columns, 15298 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0   -4.0960000e+30   1.600000e+31   4.096000e+00      0s\n",
      "    1154    1.3950315e+04   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1154 iterations and 0.02 seconds (0.03 work units)\n",
      "Optimal objective  1.395031518e+04\n",
      "\n",
      "User-callback calls 1224, time in user-callback 0.00 sec\n"
     ]
    }
   ],
   "source": [
    "const AVG_SPEED_MPM = 0.29 \n",
    "\n",
    "\n",
    "df_len = subway_data[\"linelength\"]\n",
    "\n",
    "τ = Dict{Int, Float64}()\n",
    "energy = Dict{Int, Float64}()\n",
    "\n",
    "for row in eachrow(df_len)\n",
    "    ridx = row.route_idx\n",
    "    if ridx in L\n",
    "        miles = row.\"route_length(mi)\"\n",
    "        \n",
    "        # Estimate Round Trip Time (τ):\n",
    "        # (Length / Speed) * 2 for return + 10% layover buffer\n",
    "        time_one_way = miles / AVG_SPEED_MPM\n",
    "        τ[ridx] = time_one_way * 2.0 * 1.1\n",
    "        \n",
    "        # Energy proxy: proportional to route length\n",
    "        energy[ridx] = miles \n",
    "    end\n",
    "end\n",
    "\n",
    "# Fill defaults for any missing routes (e.g., shuttles not in linelength)\n",
    "avg_tau = isempty(τ) ? 60.0 : mean(values(τ))\n",
    "avg_energy = isempty(energy) ? 10.0 : mean(values(energy))\n",
    "\n",
    "for ℓ in L\n",
    "    if !haskey(τ, ℓ)\n",
    "        τ[ℓ] = avg_tau\n",
    "        energy[ℓ] = avg_energy\n",
    "    end\n",
    "end\n",
    "\n",
    "Δ = 1      # 1 hour horizon\n",
    "T_max = 6553.0  # Fleet size limit (e.g. 600 trains system-wide)\n",
    "β = 5000.0     # Penalty for overflow (unmet demand)\n",
    "γ = 16.0       # Penalty for energy/operation cost\n",
    "λ = 0.999       # Balance parameter\n",
    "\n",
    "\n",
    "model = build_subway_model(\n",
    "    V,\n",
    "    E_track,\n",
    "    E_transfer,\n",
    "    L,\n",
    "    L_ij;\n",
    "    s      = s,\n",
    "    t      = t,\n",
    "    t_tr   = t_tr,\n",
    "    C_train = C_train,\n",
    "    Δ       = Δ,\n",
    "    τ       = τ,\n",
    "    energy  = energy,\n",
    "    T_max   = T_max,\n",
    "    β       = β,\n",
    "    γ       = γ,\n",
    "    λ       = λ,\n",
    ")\n",
    "\n",
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f7415aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STRUCTURAL INFEASIBILITY REPORT ---\n",
      "ERROR: Station 61 has net entries (+2005.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 80 has net entries (+15884.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 90 has net entries (+5401.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 92 has net entries (+2533.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 115 has net entries (+3880.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 229 has net entries (+8027.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 318 has net entries (+589.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 321 has net entries (+2162.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 356 has net entries (+1686.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 360 has net entries (+93.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 401 has net entries (+2267.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 428 has net entries (+2061.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 432 has net entries (+3203.0) but NO outgoing edges (Dead End).\n",
      "ERROR: Station 471 has net entries (+5409.0) but NO outgoing edges (Dead End).\n",
      "Fix the graph edges for the stations listed above.\n",
      "\u001b[1m14×11 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m node_idx \u001b[0m\u001b[1m stop_id \u001b[0m\u001b[1m stop_name                    \u001b[0m\u001b[1m stop_lon \u001b[0m\u001b[1m stop_lat \u001b[0m\u001b[1m station_complex_id \u001b[0m\u001b[1m ridership_morning \u001b[0m\u001b[1m ridership_evening \u001b[0m\u001b[1m net_ridership \u001b[0m\u001b[1m balanced_real \u001b[0m\u001b[1m balanced_net_ridership_int \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m String3 \u001b[0m\u001b[90m String                       \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Int64              \u001b[0m\u001b[90m Float64           \u001b[0m\u001b[90m Float64           \u001b[0m\u001b[90m Float64       \u001b[0m\u001b[90m Float64       \u001b[0m\u001b[90m Int64                      \u001b[0m\n",
      "─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   1 │       61  227      110 St-Malcolm X Plaza        -73.9518   40.7991                 441             1894.0             1397.0          497.0      2004.69                          2005\n",
      "   2 │       80  247      Flatbush Av-Brooklyn College  -73.9476   40.6328                 359             6399.0             2461.0         3938.0     15884.3                          15884\n",
      "   3 │       90  257      New Lots Av                   -73.8841   40.6662                 352             1903.0              564.0         1339.0      5400.98                          5401\n",
      "   4 │       92  302      145 St                        -73.9362   40.8204                 437             1047.0              419.0          628.0      2533.09                          2533\n",
      "   5 │      115  505      Morris Park                   -73.8605   40.8544                 446             1162.0              200.0          962.0      3880.31                          3880\n",
      "   6 │      229  A65      Ozone Park-Lefferts Blvd      -73.8258   40.686                  195             2514.0              524.0         1990.0      8026.84                          8027\n",
      "   7 │      318  F39      Neptune Av                    -73.9746   40.581                  253              425.0              279.0          146.0       588.904                          589\n",
      "   8 │      321  G07      Jamaica-Van Wyck              -73.8169   40.7026                 280             1384.0              848.0          536.0      2162.0                           2162\n",
      "   9 │      356  H11      Far Rockaway-Mott Av          -73.7554   40.604                  209             1179.0              761.0          418.0      1686.04                          1686\n",
      "  10 │      360  H15      Rockaway Park-Beach 116 St    -73.8356   40.5809                 203              169.0              146.0           23.0        92.7726                          93\n",
      "  11 │      401  L29      Canarsie-Rockaway Pkwy        -73.9018   40.6467                 138              897.0              335.0          562.0      2266.88                          2267\n",
      "  12 │      428  N10      86 St                         -73.9782   40.5927                  79              808.0              297.0          511.0      2061.16                          2061\n",
      "  13 │      432  Q05      96 St                         -73.9472   40.7843                 475             4440.0             3646.0          794.0      3202.67                          3203\n",
      "  14 │      471  R45      Bay Ridge-95 St               -74.0309   40.6166                  39             1955.0              614.0         1341.0      5409.04                          5409\n"
     ]
    }
   ],
   "source": [
    "# 1. Calculate In-Degree and Out-Degree for every node in the graph\n",
    "#    (Considering both Track and Transfer edges)\n",
    "out_degree = Dict{Int, Int}()\n",
    "in_degree = Dict{Int, Int}()\n",
    "\n",
    "for i in V\n",
    "    out_degree[i] = 0\n",
    "    in_degree[i] = 0\n",
    "end\n",
    "\n",
    "# Count Track Edges\n",
    "for (i, j) in E_track\n",
    "    out_degree[i] += 1\n",
    "    in_degree[j] += 1\n",
    "end\n",
    "\n",
    "# Count Transfer Edges\n",
    "for (i, j) in E_transfer\n",
    "    out_degree[i] += 1\n",
    "    in_degree[j] += 1\n",
    "end\n",
    "\n",
    "# 2. Identify Problematic Nodes\n",
    "println(\"--- STRUCTURAL INFEASIBILITY REPORT ---\")\n",
    "problem_found = false\n",
    "\n",
    "for i in V\n",
    "    dem = get(s, i, 0.0)\n",
    "    \n",
    "    # CASE A: Source Node (s > 0) with NO OUTGOING EDGES\n",
    "    if dem > 1e-6 && out_degree[i] == 0\n",
    "        println(\"ERROR: Station $i has net entries (+$(dem)) but NO outgoing edges (Dead End).\")\n",
    "        problem_found = true\n",
    "    end\n",
    "\n",
    "    # CASE B: Sink Node (s < 0) with NO INCOMING EDGES\n",
    "    if dem < -1e-6 && in_degree[i] == 0\n",
    "        println(\"ERROR: Station $i has net exits ($(dem)) but NO incoming edges (Unreachable).\")\n",
    "        problem_found = true\n",
    "    end\n",
    "end\n",
    "\n",
    "if !problem_found\n",
    "    println(\"No obvious source/sink directionality errors found.\")\n",
    "else\n",
    "    println(\"Fix the graph edges for the stations listed above.\")\n",
    "end\n",
    "\n",
    "# List of node indices identified as dead ends\n",
    "problem_node_idxs = [61, 80, 90, 92, 115, 229, 318, 321, 356, 360, 401, 428, 432, 471]\n",
    "\n",
    "# Filter the existing nodes_df to see the names and GTFS IDs\n",
    "problem_stations = filter(row -> row.node_idx in problem_node_idxs, nodes_df)\n",
    "\n",
    "# Print the result\n",
    "println(problem_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "17eff32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26×4 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m route_idx \u001b[0m\u001b[1m route_name \u001b[0m\u001b[1m trains_per_hour \u001b[0m\u001b[1m headway_mins \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64     \u001b[0m\u001b[90m String3    \u001b[0m\u001b[90m Float64         \u001b[0m\u001b[90m Float64      \u001b[0m\n",
      "─────┼──────────────────────────────────────────────────────\n",
      "   1 │         0  1                      2.81          21.3\n",
      "   2 │         1  2                      1.3           46.3\n",
      "   3 │         2  3                      0.0          Inf\n",
      "   4 │         3  4                      6.4            9.4\n",
      "   5 │         4  5                      3.74          16.0\n",
      "   6 │         5  6                      0.71          84.5\n",
      "   7 │         6  6X                     0.0          Inf\n",
      "   8 │         7  7                      2.46          24.4\n",
      "   9 │         8  7X                     0.0          Inf\n",
      "  10 │         9  A                      3.78          15.9\n",
      "  11 │        10  B                      0.0          Inf\n",
      "  12 │        11  C                      0.0          Inf\n",
      "  13 │        12  D                      1.89          31.7\n",
      "  14 │        13  E                      2.37          25.3\n",
      "  15 │        14  F                      1.73          34.6\n",
      "  16 │        15  FX                     0.0          Inf\n",
      "  17 │        16  G                      0.0          Inf\n",
      "  18 │        17  J                      1.75          34.3\n",
      "  19 │        18  L                      2.25          26.7\n",
      "  20 │        19  M                      0.0          Inf\n",
      "  21 │        20  N                      0.0          Inf\n",
      "  22 │        21  Q                      0.83          72.4\n",
      "  23 │        22  R                      0.0          Inf\n",
      "  24 │        23  S                     44.41           1.4\n",
      "  25 │        24  W                     15.98           3.8\n",
      "  26 │        25  Z                      0.0          Inf\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    get_optimized_frequencies(model, L, routes_df)\n",
    "\n",
    "Extracts the optimized frequency values (f) for each line from the solved JuMP model.\n",
    "Returns a DataFrame sorted by route name.\n",
    "\"\"\"\n",
    "function get_optimized_frequencies(model, L, routes_df)\n",
    "    # 1. Check if model has a solution\n",
    "    if termination_status(model) != MOI.OPTIMAL\n",
    "        @warn \"Model not optimal! Status: $(termination_status(model))\"\n",
    "        # Proceeding anyway to show partial results if available...\n",
    "    end\n",
    "\n",
    "    # 2. Create a map from Route Index -> Route Name\n",
    "    # (Assuming routes_df has :route_idx and :route_short_name)\n",
    "    idx_to_name = Dict(r.route_idx => r.route_short_name for r in eachrow(routes_df))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # 3. Iterate over all lines in set L\n",
    "    for ℓ in L\n",
    "        # Retrieve the value of the variable f for line ℓ\n",
    "        # Use JuMP.value(...) to get the numeric result\n",
    "        f_val = value(model[:f][ℓ])\n",
    "        \n",
    "        # Get the friendly name\n",
    "        r_name = get(idx_to_name, ℓ, \"Line $ℓ\")\n",
    "        \n",
    "        # Determine approx headway (minutes) if frequency > 0\n",
    "        headway_min = f_val > 1e-6 ? (60.0 / f_val) : Inf\n",
    "\n",
    "        push!(results, (\n",
    "            route_idx = ℓ, \n",
    "            route_name = r_name, \n",
    "            trains_per_hour = round(f_val, digits=2),\n",
    "            headway_mins = round(headway_min, digits=1)\n",
    "        ))\n",
    "    end\n",
    "\n",
    "    # 4. Convert to DataFrame and sort\n",
    "    df_results = DataFrame(results)\n",
    "    sort!(df_results, :route_name)\n",
    "    \n",
    "    return df_results\n",
    "end\n",
    "\n",
    "resulting_frequencies = get_optimized_frequencies(model, L, routes_df)\n",
    "println(resulting_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e03a397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Total Ridership (System-Wide): 1525774\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.525774e6"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    get_total_ridership(s)\n",
    "\n",
    "Calculates the total number of riders (passengers) modeled in the system\n",
    "by summing all positive net-ridership entries.\n",
    "\"\"\"\n",
    "function get_total_ridership(s)\n",
    "    # Sum of all positive net ridership values (Entries)\n",
    "    total_riders = sum(val for val in values(s) if val > 0)\n",
    "    \n",
    "    println(\"--------------------------------\")\n",
    "    println(\"Total Ridership (System-Wide): $(round(Int, total_riders))\")\n",
    "    println(\"--------------------------------\")\n",
    "    \n",
    "    return total_riders\n",
    "end\n",
    "\n",
    "# --- Usage ---\n",
    "# Run this after you have defined 's' (it does not strictly require the solved model, \n",
    "# as 's' is the input, but this confirms what the model attempted to route).\n",
    "get_total_ridership(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
