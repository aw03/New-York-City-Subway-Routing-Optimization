{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "42a3820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, Gurobi, CSV, DataFrames, Statistics, Distances, JuMP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "fe509ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRecursively scanning directory: .\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\MTA_Subway_Hourly_Ridership__Oct_21_2024_Evening.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\MTA_Subway_Hourly_Ridership__Oct_21_2024_Morning.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\MTA_Subway_Stations_20251204.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\agency.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\calendar.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\calendar_dates.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\linecapacity.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\linelength.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\routes.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\shapes.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\stop_times.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Summary ---\n",
      "Dataset: 'routes'\n",
      "  Shape: 29 rows × 10 columns\n",
      "  Cols:  route_id, agency_id, route_short_name, route_long_name, route_desc, route_type, route_url, route_color, route_text_color, route_sort_order\n",
      "--------------------\n",
      "Dataset: 'nodes_with_ridership'\n",
      "  Shape: 475 rows × 9 columns\n",
      "  Cols:  node_idx, stop_id, stop_name, stop_lon, stop_lat, station_complex_id, ridership_morning, ridership_evening, net_ridership\n",
      "--------------------\n",
      "Dataset: 'stops'\n",
      "  Shape: 1488 rows × 6 columns\n",
      "  Cols:  stop_id, stop_name, stop_lat, stop_lon, location_type, parent_station\n",
      "--------------------\n",
      "Dataset: 'trips'\n",
      "  Shape: 20304 rows × 6 columns\n",
      "  Cols:  route_id, trip_id, service_id, trip_headsign, direction_id, shape_id\n",
      "--------------------\n",
      "Dataset: 'MTA_Subway_Aggregated_Ridership_Oct_21_2024_Evening'\n",
      "  Shape: 424 rows × 2 columns\n",
      "  Cols:  station_complex_id, ridership\n",
      "--------------------\n",
      "Dataset: 'agency'\n",
      "  Shape: 1 rows × 6 columns\n",
      "  Cols:  agency_id, agency_name, agency_url, agency_timezone, agency_lang, agency_phone\n",
      "--------------------\n",
      "Dataset: 'nodes_with_balanced_integer_net_ridership'\n",
      "  Shape: 475 rows × 11 columns\n",
      "  Cols:  node_idx, stop_id, stop_name, stop_lon, stop_lat, station_complex_id, ridership_morning, ridership_evening, net_ridership, balanced_real, balanced_net_ridership_int\n",
      "--------------------\n",
      "Dataset: 'stop_times'\n",
      "  Shape: 562597 rows × 5 columns\n",
      "  Cols:  trip_id, stop_id, arrival_time, departure_time, stop_sequence\n",
      "--------------------\n",
      "Dataset: 'MTA_Subway_Hourly_Ridership__Oct_21_2024_Morning'\n",
      "  Shape: 15549 rows × 12 columns\n",
      "  Cols:  transit_timestamp, transit_mode, station_complex_id, station_complex, borough, payment_method, fare_class_category, ridership, transfers, latitude, longitude, Georeference\n",
      "--------------------\n",
      "Dataset: 'stop_routes'\n",
      "  Shape: 475 rows × 3 columns\n",
      "  Cols:  stop_id, stop_name, routes_at_stop\n",
      "--------------------\n",
      "Dataset: 'MTA_Subway_Aggregated_Ridership_Oct_21_2024_Morning'\n",
      "  Shape: 424 rows × 2 columns\n",
      "  Cols:  station_complex_id, ridership\n",
      "--------------------\n",
      "Dataset: 'shapes'\n",
      "  Shape: 149834 rows × 4 columns\n",
      "  Cols:  shape_id, shape_pt_sequence, shape_pt_lat, shape_pt_lon\n",
      "--------------------\n",
      "Dataset: 'edges_by_route'\n",
      "  Shape: 1039 rows × 8 columns\n",
      "  Cols:  edge_idx, from_idx, to_idx, route_idx, from_stop_id, to_stop_id, route_short_name, count\n",
      "--------------------\n",
      "Dataset: 'calendar'\n",
      "  Shape: 3 rows × 10 columns\n",
      "  Cols:  service_id, monday, tuesday, wednesday, thursday, friday, saturday, sunday, start_date, end_date\n",
      "--------------------\n",
      "Dataset: 'evening_4to8_with_gtfs'\n",
      "  Shape: 475 rows × 3 columns\n",
      "  Cols:  station_complex_id, ridership, GTFS Stop ID\n",
      "--------------------\n",
      "Dataset: 'calendar_dates'\n",
      "  Shape: 8 rows × 3 columns\n",
      "  Cols:  service_id, date, exception_type\n",
      "--------------------\n",
      "Dataset: 'nodes'\n",
      "  Shape: 475 rows × 5 columns\n",
      "  Cols:  node_idx, stop_id, stop_name, stop_lon, stop_lat\n",
      "--------------------\n",
      "Dataset: 'nodes_with_balanced_net_ridership'\n",
      "  Shape: 475 rows × 10 columns\n",
      "  Cols:  node_idx, stop_id, stop_name, stop_lon, stop_lat, station_complex_id, ridership_morning, ridership_evening, net_ridership, balanced_net_ridership\n",
      "--------------------\n",
      "Dataset: 'generated_graphs_routes'\n",
      "  Shape: 26 rows × 2 columns\n",
      "  Cols:  route_idx, route_short_name\n",
      "--------------------\n",
      "Dataset: 'linelength'\n",
      "  Shape: 26 rows × 4 columns\n",
      "  Cols:  route_idx, route_short_name, route_length(mi), route_stations(rush_hour)\n",
      "--------------------\n",
      "Dataset: 'morning_6to10_with_gtfs'\n",
      "  Shape: 475 rows × 3 columns\n",
      "  Cols:  station_complex_id, ridership, GTFS Stop ID\n",
      "--------------------\n",
      "Dataset: 'MTA_Subway_Hourly_Ridership__Oct_21_2024_Evening'\n",
      "  Shape: 15311 rows × 12 columns\n",
      "  Cols:  transit_timestamp, transit_mode, station_complex_id, station_complex, borough, payment_method, fare_class_category, ridership, transfers, latitude, longitude, Georeference\n",
      "--------------------\n",
      "Dataset: 'MTA_Subway_Stations_20251204'\n",
      "  Shape: 496 rows × 19 columns\n",
      "  Cols:  GTFS Stop ID, Station ID, Complex ID, Division, Line, Stop Name, Borough, CBD, Daytime Routes, Structure, GTFS Latitude, GTFS Longitude, North Direction Label, South Direction Label, ADA, ADA Northbound, ADA Southbound, ADA Notes, Georeference\n",
      "--------------------\n",
      "Dataset: 'linecapacity'\n",
      "  Shape: 26 rows × 5 columns\n",
      "  Cols:  route_idx, route_short_name, cars_per_train, rush_hour_capacity_per_car, total_rush_hour_capacity\n",
      "--------------------\n",
      "Dataset: 'transfer_edges'\n",
      "  Shape: 150 rows × 8 columns\n",
      "  Cols:  transfer_edge_id, from_stop_id, to_stop_id, from_idx, to_idx, transfer_type, min_transfer_time, cost\n",
      "--------------------\n",
      "Dataset: 'transfers'\n",
      "  Shape: 613 rows × 4 columns\n",
      "  Cols:  from_stop_id, to_stop_id, transfer_type, min_transfer_time\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\stops.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\transfers.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\datasets\\trips.txt\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\edges_by_route.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\nodes.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\nodes_with_balanced_integer_net_ridership.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\nodes_with_balanced_net_ridership.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\nodes_with_ridership.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\routes.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\stop_routes.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_graphs\\transfer_edges.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_turnstile_data\\MTA_Subway_Aggregated_Ridership_Oct_21_2024_Evening.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_turnstile_data\\MTA_Subway_Aggregated_Ridership_Oct_21_2024_Morning.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_turnstile_data\\evening_4to8_with_gtfs.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mParsing: .\\generated_turnstile_data\\morning_6to10_with_gtfs.csv\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSuccessfully loaded 26 datasets.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    load_repo_data(repo_path::String)\n",
    "\n",
    "Recursively walks through the specified repository path, identifies all `.csv` and `.txt` files\n",
    "(even in subfolders), and parses them into a Dictionary of DataFrames.\n",
    "\n",
    "# Arguments\n",
    "- `repo_path::String`: The local path to the cloned repository.\n",
    "\n",
    "# Returns\n",
    "- `Dict{String, DataFrame}`: A dictionary where keys are unique filenames and values are DataFrames.\n",
    "\"\"\"\n",
    "function load_repo_data(repo_path::String)\n",
    "    # Dictionary to store the parsed data\n",
    "    data_store = Dict{String, DataFrame}()\n",
    "    \n",
    "    # CSV options (assume headers exist)\n",
    "    csv_options = (header=true, stringtype=String)\n",
    "\n",
    "    if !isdir(repo_path)\n",
    "        @error \"Directory not found: $repo_path\"\n",
    "        return data_store\n",
    "    end\n",
    "\n",
    "    @info \"Recursively scanning directory: $repo_path\"\n",
    "    \n",
    "    files_found = 0\n",
    "    \n",
    "    # walkdir allows us to search subdirectories (e.g., /data, /src)\n",
    "    for (root, dirs, files) in walkdir(repo_path)\n",
    "        for file in files\n",
    "            # Check for valid extensions\n",
    "            if endswith(lowercase(file), \".csv\") || endswith(lowercase(file), \".txt\")\n",
    "                \n",
    "                files_found += 1\n",
    "                full_path = joinpath(root, file)\n",
    "                dataset_name = splitext(file)[1]\n",
    "                \n",
    "                # Handle duplicate filenames in different folders by appending parent folder name\n",
    "                if haskey(data_store, dataset_name)\n",
    "                    parent_folder = basename(root)\n",
    "                    dataset_name = \"$(parent_folder)_$(dataset_name)\"\n",
    "                end\n",
    "\n",
    "                try\n",
    "                    @info \"Parsing: $full_path\"\n",
    "                    df = CSV.read(full_path, DataFrame; csv_options...)\n",
    "                    data_store[dataset_name] = df\n",
    "                catch e\n",
    "                    # Only warn, don't crash, if a file is malformed\n",
    "                    @warn \"Skipping $file: Unable to parse as CSV table.\"\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if files_found == 0\n",
    "        @warn \"No CSV or TXT files were found in $repo_path or its subdirectories.\"\n",
    "        @info \"Current working directory contains: $(readdir(repo_path))\"\n",
    "    else\n",
    "        @info \"Successfully loaded $(length(data_store)) datasets.\"\n",
    "    end\n",
    "\n",
    "    return data_store\n",
    "end\n",
    "\"\"\"\n",
    "    summarize_data(data::Dict{String, DataFrame})\n",
    "\n",
    "Prints a brief summary of the loaded datasets.\n",
    "\"\"\"\n",
    "function summarize_data(data::Dict{String, DataFrame})\n",
    "    println(\"\\n--- Data Summary ---\")\n",
    "    for (name, df) in data\n",
    "        println(\"Dataset: '$name'\")\n",
    "        println(\"  Shape: $(nrow(df)) rows × $(ncol(df)) columns\")\n",
    "        println(\"  Cols:  $(join(names(df), \", \"))\")\n",
    "        println(\"--------------------\")\n",
    "    end\n",
    "end\n",
    "\n",
    "repo_path = \".\" \n",
    "\n",
    "# 2. Load the data\n",
    "\n",
    "subway_data = load_repo_data(repo_path)\n",
    "\n",
    "# 3. Print summary\n",
    "summarize_data(subway_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "eff59c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "build_subway_model (generic function with 1 method)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    build_subway_model(V, E_track, E_transfer, L, L_ij; kwargs...) -> model\n",
    "\n",
    "Builds the Gurobi/JuMP model for the subway optimization problem with:\n",
    "- track edges E_track\n",
    "- transfer edges E_transfer\n",
    "- line set L\n",
    "- per-edge line sets L_ij\n",
    "\n",
    "This ONLY builds the optimizer; it does not read any CSVs.\n",
    "You must construct the sets and parameter dictionaries before calling it.\n",
    "\n",
    "Arguments\n",
    "---------\n",
    "V::Vector{Station}                # stations (any index type: Int, String, etc.)\n",
    "E_track::Vector{Tuple{Station,Station}}\n",
    "E_transfer::Vector{Tuple{Station,Station}}\n",
    "L::Vector{Line}\n",
    "L_ij::Dict{Tuple{Station,Station},Vector{Line}}\n",
    "\n",
    "Keyword parameters (all REQUIRED)\n",
    "---------------------------------\n",
    "s::Dict{Station,Float64}                             # s_i\n",
    "t::Dict{Tuple{Station,Station,Line},Float64}         # t_{ijℓ}\n",
    "t_tr::Dict{Tuple{Station,Station},Float64}           # t^{tr}_{ij}\n",
    "C_train::Float64                                     # C_train\n",
    "Δ::Float64                                           # Δ\n",
    "τ::Dict{Line,Float64}                                # τ_ℓ\n",
    "energy::Dict{Line,Float64}                           # energy_ℓ\n",
    "T_max::Float64                                       # T_max\n",
    "β::Float64                                           # β\n",
    "γ::Float64                                           # γ\n",
    "λ::Float64                                           # λ ∈ [0,1]\n",
    "\n",
    "Optional\n",
    "--------\n",
    "shared_track_constraint::Bool = true\n",
    "\n",
    "Returns\n",
    "-------\n",
    "::JuMP.Model (with Gurobi as optimizer)\n",
    "\"\"\"\n",
    "\n",
    "function build_subway_model(\n",
    "    V,\n",
    "    E_track,\n",
    "    E_transfer,\n",
    "    L,\n",
    "    L_ij;\n",
    "    s,\n",
    "    t,\n",
    "    t_tr,\n",
    "    C_train,   # Dict{Line,Float64}\n",
    "    Δ,\n",
    "    τ,\n",
    "    energy,\n",
    "    T_max,\n",
    "    β,\n",
    "    γ,\n",
    "    λ,\n",
    "    shared_track_constraint::Bool = true,\n",
    ")\n",
    "\n",
    "    model = Model(Gurobi.Optimizer)\n",
    "\n",
    "    # -------------------------\n",
    "    # 1. Symmetrize the Network\n",
    "    # -------------------------\n",
    "    # We build a set of triplets that allows flow in BOTH directions \n",
    "    # for every physical connection provided.\n",
    "    \n",
    "    triplet_set = Set{Tuple{eltype(V),eltype(V),eltype(L)}}()\n",
    "    \n",
    "    # Helper to register a directed edge (i->j) and its reverse (j->i)\n",
    "    function register_edge(i, j, lines)\n",
    "        for ℓ in lines\n",
    "            push!(triplet_set, (i, j, ℓ))\n",
    "            push!(triplet_set, (j, i, ℓ))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Process all input track edges\n",
    "    for (i, j) in E_track\n",
    "        lines = get(L_ij, (i, j), Vector{eltype(L)}())\n",
    "        register_edge(i, j, lines)\n",
    "    end\n",
    "\n",
    "    track_triplets = collect(triplet_set)\n",
    "    \n",
    "    # Identify unique edges (directional) for iterating constraints\n",
    "    # (Group by i, j)\n",
    "    segments = Set{Tuple{eltype(V), eltype(V)}}()\n",
    "    for (i, j, ℓ) in track_triplets\n",
    "        push!(segments, (i, j))\n",
    "    end\n",
    "\n",
    "    # -------------------------\n",
    "    # Variables\n",
    "    # -------------------------\n",
    "    @variable(model, x[track_triplets] >= 0)\n",
    "    @variable(model, y[E_transfer] >= 0)\n",
    "    @variable(model, f[L] >= 0)\n",
    "    @variable(model, overflow[track_triplets] >= 0)\n",
    "\n",
    "    # -------------------------\n",
    "    # (1) Flow Conservation\n",
    "    # -------------------------\n",
    "    for i in V\n",
    "        # Flow leaving i via track\n",
    "        out_track = sum(\n",
    "            x[(i, j, ℓ)] \n",
    "            for (start_node, j, ℓ) in track_triplets \n",
    "            if start_node == i;\n",
    "            init = 0.0\n",
    "        )\n",
    "\n",
    "        # Flow leaving i via transfer\n",
    "        out_transfer = sum(\n",
    "            y[(i, j)] \n",
    "            for (start_node, j) in E_transfer \n",
    "            if start_node == i;\n",
    "            init = 0.0\n",
    "        )\n",
    "\n",
    "        # Flow entering i via track\n",
    "        in_track = sum(\n",
    "            x[(k, i, ℓ)] \n",
    "            for (k, end_node, ℓ) in track_triplets \n",
    "            if end_node == i;\n",
    "            init = 0.0\n",
    "        )\n",
    "\n",
    "        # Flow entering i via transfer\n",
    "        in_transfer = sum(\n",
    "            y[(k, i)] \n",
    "            for (k, end_node) in E_transfer \n",
    "            if end_node == i;\n",
    "            init = 0.0\n",
    "        )\n",
    "\n",
    "        @constraint(model, out_track + out_transfer - in_track - in_transfer == s[i])\n",
    "    end\n",
    "    min_frequency = 2.0  # At least 2 trains per hour per line\n",
    "    for ℓ in L\n",
    "        @constraint(model, f[ℓ] >= min_frequency)\n",
    "    end\n",
    "    # -------------------------\n",
    "    # (2) Capacity\n",
    "    # -------------------------\n",
    "    for (i, j, ℓ) in track_triplets\n",
    "        # Note: We assume C_train is per-line. \n",
    "        # Since we use C_train[ℓ], it applies correctly to both directions.\n",
    "        @constraint(model, x[(i, j, ℓ)] - overflow[(i, j, ℓ)] <= C_train[ℓ] * f[ℓ] * Δ)\n",
    "    end\n",
    "\n",
    "    # -------------------------\n",
    "    # (3) Shared Track\n",
    "    # -------------------------\n",
    "    # We iterate over our discovered segments, not the raw input E_track\n",
    "    if shared_track_constraint\n",
    "        for (i, j) in segments\n",
    "            # Find all lines serving this specific directed segment\n",
    "            # (We filter the triplets manually or could pre-build a dict)\n",
    "            lines_on_segment = [l for (u, v, l) in track_triplets if u == i && v == j]\n",
    "            \n",
    "            if !isempty(lines_on_segment)\n",
    "                lhs = sum(x[(i, j, ℓ)] - overflow[(i, j, ℓ)] for ℓ in lines_on_segment)\n",
    "                rhs = sum(C_train[ℓ] * f[ℓ] * Δ for ℓ in lines_on_segment)\n",
    "                @constraint(model, lhs <= rhs)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # -------------------------\n",
    "    # (4) Fleet/Energy Limit\n",
    "    # -------------------------\n",
    "    @constraint(model, sum(f[ℓ] * τ[ℓ] for ℓ in L; init=0.0) <= T_max)\n",
    "\n",
    "    # -------------------------\n",
    "    # Objective\n",
    "    # -------------------------\n",
    "    \n",
    "    # Helper to find cost t for (i, j, ℓ) safely\n",
    "    # If t[(i, j, ℓ)] missing, try t[(j, i, ℓ)]\n",
    "    function get_cost(i, j, ℓ)\n",
    "        if haskey(t, (i, j, ℓ))\n",
    "            return t[(i, j, ℓ)]\n",
    "        elseif haskey(t, (j, i, ℓ))\n",
    "            return t[(j, i, ℓ)]\n",
    "        else\n",
    "            return 1.0 # Default fallback\n",
    "        end\n",
    "    end\n",
    "\n",
    "    passenger_time_expr =\n",
    "        sum(get_cost(i, j, ℓ) * x[(i, j, ℓ)] for (i, j, ℓ) in track_triplets; init=0.0) +\n",
    "        sum(t_tr[(i, j)] * y[(i, j)] for (i, j) in E_transfer; init=0.0)\n",
    "\n",
    "    overflow_expr = β * sum(overflow[triplet] for triplet in track_triplets; init=0.0)\n",
    "\n",
    "    energy_expr = γ * sum(energy[ℓ] * f[ℓ] for ℓ in L; init=0.0)\n",
    "\n",
    "    @objective(model, Min,\n",
    "        (1 - λ) * (passenger_time_expr + overflow_expr) +\n",
    "        λ * energy_expr\n",
    "    )\n",
    "\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "af0da5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>150×8 DataFrame</span></div><div style = \"float: right; font-style: italic;\"><span>125 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"columnLabelRow\"><th class = \"stubheadLabel\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">transfer_edge_id</th><th style = \"text-align: left;\">from_stop_id</th><th style = \"text-align: left;\">to_stop_id</th><th style = \"text-align: left;\">from_idx</th><th style = \"text-align: left;\">to_idx</th><th style = \"text-align: left;\">transfer_type</th><th style = \"text-align: left;\">min_transfer_time</th><th style = \"text-align: left;\">cost</th></tr><tr class = \"columnLabelRow\"><th class = \"stubheadLabel\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String3\" style = \"text-align: left;\">String3</th><th title = \"String3\" style = \"text-align: left;\">String3</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">112</td><td style = \"text-align: left;\">A09</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">183</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">125</td><td style = \"text-align: left;\">A24</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">196</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">127</td><td style = \"text-align: left;\">725</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">174</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">3</td><td style = \"text-align: left;\">127</td><td style = \"text-align: left;\">902</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">177</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">4</td><td style = \"text-align: left;\">127</td><td style = \"text-align: left;\">A27</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">198</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">300</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">5</td><td style = \"text-align: left;\">127</td><td style = \"text-align: left;\">R16</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">444</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">6</td><td style = \"text-align: left;\">132</td><td style = \"text-align: left;\">D19</td><td style = \"text-align: right;\">29</td><td style = \"text-align: right;\">263</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">300</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">7</td><td style = \"text-align: left;\">132</td><td style = \"text-align: left;\">L02</td><td style = \"text-align: right;\">29</td><td style = \"text-align: right;\">379</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">8</td><td style = \"text-align: left;\">222</td><td style = \"text-align: left;\">415</td><td style = \"text-align: right;\">57</td><td style = \"text-align: right;\">105</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">9</td><td style = \"text-align: left;\">228</td><td style = \"text-align: left;\">A36</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">205</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">10</td><td style = \"text-align: left;\">228</td><td style = \"text-align: left;\">E01</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">286</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">11</td><td style = \"text-align: left;\">228</td><td style = \"text-align: left;\">R25</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">453</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">420</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">12</td><td style = \"text-align: left;\">229</td><td style = \"text-align: left;\">418</td><td style = \"text-align: right;\">63</td><td style = \"text-align: right;\">107</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">300</td><td style = \"text-align: right;\">1</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: left;\">&vellip;</td><td style = \"text-align: left;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">139</td><td style = \"text-align: right;\">138</td><td style = \"text-align: left;\">R23</td><td style = \"text-align: left;\">Q01</td><td style = \"text-align: right;\">451</td><td style = \"text-align: right;\">429</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">140</td><td style = \"text-align: right;\">139</td><td style = \"text-align: left;\">R25</td><td style = \"text-align: left;\">E01</td><td style = \"text-align: right;\">453</td><td style = \"text-align: right;\">286</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">240</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">141</td><td style = \"text-align: right;\">140</td><td style = \"text-align: left;\">R25</td><td style = \"text-align: left;\">A36</td><td style = \"text-align: right;\">453</td><td style = \"text-align: right;\">205</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">420</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">142</td><td style = \"text-align: right;\">141</td><td style = \"text-align: left;\">R25</td><td style = \"text-align: left;\">228</td><td style = \"text-align: right;\">453</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">420</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">143</td><td style = \"text-align: right;\">142</td><td style = \"text-align: left;\">R28</td><td style = \"text-align: left;\">232</td><td style = \"text-align: right;\">456</td><td style = \"text-align: right;\">66</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">144</td><td style = \"text-align: right;\">143</td><td style = \"text-align: left;\">R28</td><td style = \"text-align: left;\">423</td><td style = \"text-align: right;\">456</td><td style = \"text-align: right;\">110</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">145</td><td style = \"text-align: right;\">144</td><td style = \"text-align: left;\">R29</td><td style = \"text-align: left;\">A41</td><td style = \"text-align: right;\">457</td><td style = \"text-align: right;\">208</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">90</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">146</td><td style = \"text-align: right;\">145</td><td style = \"text-align: left;\">R31</td><td style = \"text-align: left;\">235</td><td style = \"text-align: right;\">459</td><td style = \"text-align: right;\">69</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">147</td><td style = \"text-align: right;\">146</td><td style = \"text-align: left;\">R31</td><td style = \"text-align: left;\">D24</td><td style = \"text-align: right;\">459</td><td style = \"text-align: right;\">267</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">300</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">148</td><td style = \"text-align: right;\">147</td><td style = \"text-align: left;\">R33</td><td style = \"text-align: left;\">F23</td><td style = \"text-align: right;\">461</td><td style = \"text-align: right;\">304</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">149</td><td style = \"text-align: right;\">148</td><td style = \"text-align: left;\">S01</td><td style = \"text-align: left;\">A45</td><td style = \"text-align: right;\">472</td><td style = \"text-align: right;\">212</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">150</td><td style = \"text-align: right;\">149</td><td style = \"text-align: left;\">S04</td><td style = \"text-align: left;\">239</td><td style = \"text-align: right;\">474</td><td style = \"text-align: right;\">73</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">1</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& transfer\\_edge\\_id & from\\_stop\\_id & to\\_stop\\_id & from\\_idx & to\\_idx & transfer\\_type & min\\_transfer\\_time & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String3 & String3 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0 & 112 & A09 & 9 & 183 & 2 & 180 & $\\dots$ \\\\\n",
       "\t2 & 1 & 125 & A24 & 22 & 196 & 2 & 180 & $\\dots$ \\\\\n",
       "\t3 & 2 & 127 & 725 & 24 & 174 & 2 & 180 & $\\dots$ \\\\\n",
       "\t4 & 3 & 127 & 902 & 24 & 177 & 2 & 180 & $\\dots$ \\\\\n",
       "\t5 & 4 & 127 & A27 & 24 & 198 & 2 & 300 & $\\dots$ \\\\\n",
       "\t6 & 5 & 127 & R16 & 24 & 444 & 2 & 180 & $\\dots$ \\\\\n",
       "\t7 & 6 & 132 & D19 & 29 & 263 & 2 & 300 & $\\dots$ \\\\\n",
       "\t8 & 7 & 132 & L02 & 29 & 379 & 2 & 180 & $\\dots$ \\\\\n",
       "\t9 & 8 & 222 & 415 & 57 & 105 & 2 & 180 & $\\dots$ \\\\\n",
       "\t10 & 9 & 228 & A36 & 62 & 205 & 2 & 180 & $\\dots$ \\\\\n",
       "\t11 & 10 & 228 & E01 & 62 & 286 & 2 & 180 & $\\dots$ \\\\\n",
       "\t12 & 11 & 228 & R25 & 62 & 453 & 2 & 420 & $\\dots$ \\\\\n",
       "\t13 & 12 & 229 & 418 & 63 & 107 & 2 & 300 & $\\dots$ \\\\\n",
       "\t14 & 13 & 229 & A38 & 63 & 206 & 2 & 180 & $\\dots$ \\\\\n",
       "\t15 & 14 & 229 & M22 & 63 & 418 & 2 & 300 & $\\dots$ \\\\\n",
       "\t16 & 15 & 232 & 423 & 66 & 110 & 2 & 300 & $\\dots$ \\\\\n",
       "\t17 & 16 & 232 & R28 & 66 & 456 & 2 & 180 & $\\dots$ \\\\\n",
       "\t18 & 17 & 235 & D24 & 69 & 267 & 2 & 180 & $\\dots$ \\\\\n",
       "\t19 & 18 & 235 & R31 & 69 & 459 & 2 & 180 & $\\dots$ \\\\\n",
       "\t20 & 19 & 239 & S04 & 73 & 474 & 2 & 180 & $\\dots$ \\\\\n",
       "\t21 & 20 & 254 & L26 & 87 & 398 & 2 & 300 & $\\dots$ \\\\\n",
       "\t22 & 21 & 414 & D11 & 104 & 255 & 2 & 180 & $\\dots$ \\\\\n",
       "\t23 & 22 & 415 & 222 & 105 & 57 & 2 & 180 & $\\dots$ \\\\\n",
       "\t24 & 23 & 418 & 229 & 107 & 63 & 2 & 300 & $\\dots$ \\\\\n",
       "\t25 & 24 & 418 & A38 & 107 & 206 & 2 & 180 & $\\dots$ \\\\\n",
       "\t26 & 25 & 418 & M22 & 107 & 418 & 2 & 300 & $\\dots$ \\\\\n",
       "\t27 & 26 & 423 & 232 & 110 & 66 & 2 & 300 & $\\dots$ \\\\\n",
       "\t28 & 27 & 423 & R28 & 110 & 456 & 2 & 180 & $\\dots$ \\\\\n",
       "\t29 & 28 & 629 & B08 & 142 & 232 & 2 & 300 & $\\dots$ \\\\\n",
       "\t30 & 29 & 629 & R11 & 142 & 440 & 2 & 180 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m150×8 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m transfer_edge_id \u001b[0m\u001b[1m from_stop_id \u001b[0m\u001b[1m to_stop_id \u001b[0m\u001b[1m from_idx \u001b[0m\u001b[1m to_idx \u001b[0m\u001b[1m transfer_\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64            \u001b[0m\u001b[90m String3      \u001b[0m\u001b[90m String3    \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Int64    \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │                0  112           A09                9     183            ⋯\n",
       "   2 │                1  125           A24               22     196\n",
       "   3 │                2  127           725               24     174\n",
       "   4 │                3  127           902               24     177\n",
       "   5 │                4  127           A27               24     198            ⋯\n",
       "   6 │                5  127           R16               24     444\n",
       "   7 │                6  132           D19               29     263\n",
       "   8 │                7  132           L02               29     379\n",
       "   9 │                8  222           415               57     105            ⋯\n",
       "  10 │                9  228           A36               62     205\n",
       "  11 │               10  228           E01               62     286\n",
       "  ⋮  │        ⋮               ⋮            ⋮          ⋮        ⋮           ⋮   ⋱\n",
       " 141 │              140  R25           A36              453     205\n",
       " 142 │              141  R25           228              453      62            ⋯\n",
       " 143 │              142  R28           232              456      66\n",
       " 144 │              143  R28           423              456     110\n",
       " 145 │              144  R29           A41              457     208\n",
       " 146 │              145  R31           235              459      69            ⋯\n",
       " 147 │              146  R31           D24              459     267\n",
       " 148 │              147  R33           F23              461     304\n",
       " 149 │              148  S01           A45              472     212\n",
       " 150 │              149  S04           239              474      73            ⋯\n",
       "\u001b[36m                                                  3 columns and 129 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "nodes_df      = CSV.read(\"generated_graphs\\\\nodes_with_balanced_integer_net_ridership.csv\", DataFrame)\n",
    "routes_df     = CSV.read(\"generated_graphs\\\\routes.csv\", DataFrame)\n",
    "edges_df      = CSV.read(\"generated_graphs\\\\edges_by_route.csv\", DataFrame)\n",
    "transfers_df  = CSV.read(\"generated_graphs\\\\transfer_edges.csv\", DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3496e20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const Station = Int\n",
    "const Line    = Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "e3987b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(475,)\n",
      "(26,)\n"
     ]
    }
   ],
   "source": [
    "V = sort(unique(Station.(nodes_df.node_idx)))      # stations\n",
    "L = sort(unique(Line.(routes_df.route_idx)))       # lines\n",
    "println(size(V))\n",
    "println(size(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "624ab6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556,)"
     ]
    }
   ],
   "source": [
    "E_track = unique([(Station(row.from_idx), Station(row.to_idx)) \n",
    "                  for row in eachrow(edges_df)])\n",
    "print(size(E_track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "2e2db7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Tuple{Int64, Int64}, Vector{Int64}} with 556 entries:\n",
       "  (126, 127) => [5]\n",
       "  (359, 360) => [9, 23]\n",
       "  (55, 56)   => [1, 4]\n",
       "  (117, 118) => [5, 6]\n",
       "  (213, 214) => [9, 11]\n",
       "  (7, 8)     => [0]\n",
       "  (223, 224) => [9]\n",
       "  (14, 15)   => [0]\n",
       "  (397, 398) => [18]\n",
       "  (433, 434) => [20, 24]\n",
       "  (178, 179) => [9]\n",
       "  (267, 268) => [10, 21]\n",
       "  (368, 370) => [17]\n",
       "  (121, 122) => [5, 6]\n",
       "  (436, 437) => [20, 24]\n",
       "  (473, 474) => [23]\n",
       "  (151, 152) => [3, 5, 6]\n",
       "  (26, 27)   => [0, 1]\n",
       "  (154, 155) => [7, 8]\n",
       "  (308, 309) => [14, 15]\n",
       "  (336, 337) => [16]\n",
       "  (171, 172) => [7, 8]\n",
       "  (345, 346) => [16]\n",
       "  (261, 262) => [14, 15, 19]\n",
       "  (444, 445) => [20, 24, 21, 22]\n",
       "  ⋮          => ⋮"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_ij = Dict{Tuple{Station,Station}, Vector{Line}}()\n",
    "\n",
    "for row in eachrow(edges_df)\n",
    "    i = Station(row.from_idx)\n",
    "    j = Station(row.to_idx)\n",
    "    ℓ = Line(row.route_idx)\n",
    "    key = (i, j)\n",
    "    if haskey(L_ij, key)\n",
    "        push!(L_ij[key], ℓ)\n",
    "    else\n",
    "        L_ij[key] = [ℓ]\n",
    "    end\n",
    "end\n",
    "\n",
    "# Remove duplicates within each vector, in case the same route appears multiple times\n",
    "for lines in values(L_ij)\n",
    "    unique!(lines)\n",
    "end\n",
    "L_ij\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "bcc87ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "E_transfer = unique([(Station(row.from_idx), Station(row.to_idx))\n",
    "                     for row in eachrow(transfers_df)])\n",
    "println(size(E_transfer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "dc190808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Tuple{Int64, Int64}, Float64} with 150 entries:\n",
       "  (416, 429) => 1.0\n",
       "  (63, 418)  => 1.0\n",
       "  (472, 212) => 1.0\n",
       "  (429, 152) => 1.0\n",
       "  (172, 144) => 1.0\n",
       "  (24, 177)  => 1.0\n",
       "  (212, 472) => 1.0\n",
       "  (416, 451) => 1.0\n",
       "  (198, 174) => 1.0\n",
       "  (453, 205) => 1.0\n",
       "  (453, 62)  => 1.0\n",
       "  (429, 451) => 1.0\n",
       "  (29, 263)  => 1.0\n",
       "  (335, 294) => 1.0\n",
       "  (456, 66)  => 1.0\n",
       "  (177, 444) => 1.0\n",
       "  (422, 238) => 1.0\n",
       "  (169, 335) => 1.0\n",
       "  (198, 177) => 1.0\n",
       "  (173, 260) => 1.0\n",
       "  (176, 172) => 1.0\n",
       "  (73, 474)  => 1.0\n",
       "  (107, 63)  => 1.0\n",
       "  (379, 263) => 1.0\n",
       "  (148, 448) => 1.0\n",
       "  ⋮          => ⋮"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_tr = Dict((i, j) => 1.0 for (i, j) in E_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b316e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Dict{Tuple{Station,Station,Line}, Float64}()\n",
    "\n",
    "for row in eachrow(edges_df)\n",
    "    i = Station(row.from_idx)\n",
    "    j = Station(row.to_idx)\n",
    "    ℓ = Line(row.route_idx)\n",
    "    key = (i, j, ℓ)\n",
    "    \n",
    "    # If every segment has the same unit cost:\n",
    "    t[key] = 1.0\n",
    "\n",
    "    # Later you can replace that with actual in-train travel time per edge\n",
    "    # t[key] = real_travel_time_in_hours\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "5bc1ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Dict{Station, Float64}()\n",
    "\n",
    "for row in eachrow(nodes_df)\n",
    "    i = Station(row.node_idx)\n",
    "    s[i] = Float64(row.balanced_net_ridership_int)\n",
    "end\n",
    "\n",
    "# Optionally, ensure every station in V has an entry, even if 0:\n",
    "for i in V\n",
    "    if !haskey(s, i)\n",
    "        s[i] = 0.0\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "86466c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a mapping from Name -> ID using the ROUTES dataframe (the source of truth for the model)\n",
    "name_to_id = Dict(row.route_short_name => Line(row.route_idx) for row in eachrow(routes_df))\n",
    "\n",
    "linecap_df = CSV.read(\"datasets\\\\linecapacity.csv\", DataFrame)\n",
    "\n",
    "C_train = Dict{Line, Float64}()\n",
    "\n",
    "# 2. Iterate through linecapacity and assign to the CORRECT model index\n",
    "for row in eachrow(linecap_df)\n",
    "    r_name = row.route_short_name\n",
    "    \n",
    "    if haskey(name_to_id, r_name)\n",
    "        ℓ = name_to_id[r_name]\n",
    "        C_train[ℓ] = Float64(row.total_rush_hour_capacity)\n",
    "    else\n",
    "        @warn \"Capacity data found for route '$r_name' but it is not in the graph.\"\n",
    "    end\n",
    "end\n",
    "\n",
    "# 3. Safety Check: Ensure all lines in L have a capacity\n",
    "for ℓ in L\n",
    "    if !haskey(C_train, ℓ)\n",
    "        @warn \"No capacity defined for route index $ℓ. Defaulting to 1000.\"\n",
    "        C_train[ℓ] = 1000.0 \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "78ad6b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2703606\n",
      "Academic license 2703606 - for non-commercial use only - registered to ju___@mit.edu\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i9-14900K, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 24 physical cores, 32 logical processors, using up to 32 threads\n",
      "\n",
      "Academic license 2703606 - for non-commercial use only - registered to ju___@mit.edu\n",
      "Optimize a model with 3692 rows, 4332 columns and 16976 nonzeros\n",
      "Model fingerprint: 0x184f685e\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+03]\n",
      "  Objective range  [5e-01, 3e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 4e+04]\n",
      "Presolve removed 574 rows and 111 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 3118 rows, 4221 columns, 15268 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0   -3.2000000e+32   1.600000e+31   3.200000e+02      0s\n",
      "    2042    8.2945520e+09   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2042 iterations and 0.06 seconds (0.07 work units)\n",
      "Optimal objective  8.294552048e+09\n",
      "\n",
      "User-callback calls 2113, time in user-callback 0.00 sec\n"
     ]
    }
   ],
   "source": [
    "const AVG_SPEED_MPM = 0.29 \n",
    "\n",
    "\n",
    "df_len = subway_data[\"linelength\"]\n",
    "\n",
    "τ = Dict{Int, Float64}()\n",
    "energy = Dict{Int, Float64}()\n",
    "\n",
    "for row in eachrow(df_len)\n",
    "    ridx = row.route_idx\n",
    "    if ridx in L\n",
    "        miles = row.\"route_length(mi)\"\n",
    "        \n",
    "        # Estimate Round Trip Time (τ):\n",
    "        # (Length / Speed) * 2 for return + 10% layover buffer\n",
    "        time_one_way = miles / AVG_SPEED_MPM\n",
    "        τ[ridx] = time_one_way * 2.0 * 1.1\n",
    "        \n",
    "        # Energy proxy: proportional to route length\n",
    "        energy[ridx] = miles \n",
    "    end\n",
    "end\n",
    "\n",
    "# Fill defaults for any missing routes (e.g., shuttles not in linelength)\n",
    "avg_tau = isempty(τ) ? 60.0 : mean(values(τ))\n",
    "avg_energy = isempty(energy) ? 10.0 : mean(values(energy))\n",
    "\n",
    "for ℓ in L\n",
    "    if !haskey(τ, ℓ)\n",
    "        τ[ℓ] = avg_tau\n",
    "        energy[ℓ] = avg_energy\n",
    "    end\n",
    "end\n",
    "\n",
    "Δ = 1      # 1 hour horizon\n",
    "T_max = 30000.0  # train hours limit\n",
    "β = 50000.0     # Penalty for overflow (unmet demand)\n",
    "γ = 16.0       # Penalty for energy/operation cost\n",
    "λ = 0.5       # Balance parameter\n",
    "\n",
    "\n",
    "model = build_subway_model(\n",
    "    V,\n",
    "    E_track,\n",
    "    E_transfer,\n",
    "    L,\n",
    "    L_ij;\n",
    "    s      = s,\n",
    "    t      = t,\n",
    "    t_tr   = t_tr,\n",
    "    C_train = C_train,\n",
    "    Δ       = Δ,\n",
    "    τ       = τ,\n",
    "    energy  = energy,\n",
    "    T_max   = T_max,\n",
    "    β       = β,\n",
    "    γ       = γ,\n",
    "    λ       = λ,\n",
    ")\n",
    "\n",
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "17eff32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26×4 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m route_idx \u001b[0m\u001b[1m route_name \u001b[0m\u001b[1m trains_per_hour \u001b[0m\u001b[1m headway_mins \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64     \u001b[0m\u001b[90m String3    \u001b[0m\u001b[90m Float64         \u001b[0m\u001b[90m Float64      \u001b[0m\n",
      "─────┼──────────────────────────────────────────────────────\n",
      "   1 │         0  1                      6.44           9.3\n",
      "   2 │         1  2                      2.0           30.0\n",
      "   3 │         2  3                      2.0           30.0\n",
      "   4 │         3  4                     22.01           2.7\n",
      "   5 │         4  5                     11.42           5.3\n",
      "   6 │         5  6                      7.63           7.9\n",
      "   7 │         6  6X                     2.0           30.0\n",
      "   8 │         7  7                      6.35           9.5\n",
      "   9 │         8  7X                    13.49           4.4\n",
      "  10 │         9  A                      9.66           6.2\n",
      "  11 │        10  B                      2.0           30.0\n",
      "  12 │        11  C                      2.0           30.0\n",
      "  13 │        12  D                      5.19          11.6\n",
      "  14 │        13  E                      5.42          11.1\n",
      "  15 │        14  F                     34.15           1.8\n",
      "  16 │        15  FX                     2.0           30.0\n",
      "  17 │        16  G                      3.1           19.3\n",
      "  18 │        17  J                      4.61          13.0\n",
      "  19 │        18  L                     18.18           3.3\n",
      "  20 │        19  M                      5.87          10.2\n",
      "  21 │        20  N                      2.55          23.5\n",
      "  22 │        21  Q                     10.5            5.7\n",
      "  23 │        22  R                      5.53          10.9\n",
      "  24 │        23  S                      2.69          22.3\n",
      "  25 │        24  W                     10.37           5.8\n",
      "  26 │        25  Z                      2.0           30.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    get_optimized_frequencies(model, L, routes_df)\n",
    "\n",
    "Extracts the optimized frequency values (f) for each line from the solved JuMP model.\n",
    "Returns a DataFrame sorted by route name.\n",
    "\"\"\"\n",
    "function get_optimized_frequencies(model, L, routes_df)\n",
    "    # 1. Check if model has a solution\n",
    "    if termination_status(model) != MOI.OPTIMAL\n",
    "        @warn \"Model not optimal! Status: $(termination_status(model))\"\n",
    "        # Proceeding anyway to show partial results if available...\n",
    "    end\n",
    "\n",
    "    # 2. Create a map from Route Index -> Route Name\n",
    "    # (Assuming routes_df has :route_idx and :route_short_name)\n",
    "    idx_to_name = Dict(r.route_idx => r.route_short_name for r in eachrow(routes_df))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # 3. Iterate over all lines in set L\n",
    "    for ℓ in L\n",
    "        # Retrieve the value of the variable f for line ℓ\n",
    "        # Use JuMP.value(...) to get the numeric result\n",
    "        f_val = value(model[:f][ℓ])\n",
    "        \n",
    "        # Get the friendly name\n",
    "        r_name = get(idx_to_name, ℓ, \"Line $ℓ\")\n",
    "        \n",
    "        # Determine approx headway (minutes) if frequency > 0\n",
    "        headway_min = f_val > 1e-6 ? (60.0 / f_val) : Inf\n",
    "\n",
    "        push!(results, (\n",
    "            route_idx = ℓ, \n",
    "            route_name = r_name, \n",
    "            trains_per_hour = round(f_val, digits=2),\n",
    "            headway_mins = round(headway_min, digits=1)\n",
    "        ))\n",
    "    end\n",
    "\n",
    "    # 4. Convert to DataFrame and sort\n",
    "    df_results = DataFrame(results)\n",
    "    sort!(df_results, :route_name)\n",
    "    \n",
    "    return df_results\n",
    "end\n",
    "\n",
    "resulting_frequencies = get_optimized_frequencies(model, L, routes_df)\n",
    "println(resulting_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "e03a397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Total Ridership (System-Wide): 1525774\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.525774e6"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    get_total_ridership(s)\n",
    "\n",
    "Calculates the total number of riders (passengers) modeled in the system\n",
    "by summing all positive net-ridership entries.\n",
    "\"\"\"\n",
    "function get_total_ridership(s)\n",
    "    # Sum of all positive net ridership values (Entries)\n",
    "    total_riders = sum(val for val in values(s) if val > 0)\n",
    "    \n",
    "    println(\"--------------------------------\")\n",
    "    println(\"Total Ridership (System-Wide): $(round(Int, total_riders))\")\n",
    "    println(\"--------------------------------\")\n",
    "    \n",
    "    return total_riders\n",
    "end\n",
    "\n",
    "# --- Usage ---\n",
    "# Run this after you have defined 's' (it does not strictly require the solved model, \n",
    "# as 's' is the input, but this confirms what the model attempted to route).\n",
    "get_total_ridership(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "04dc1e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DIAGNOSTIC INFORMATION ===\n",
      "Objective Value: 8.294552048349441e9\n",
      "Termination Status: OPTIMAL\n",
      "\n",
      "Fleet Constraint:\n",
      "  Used: 30000.0 / 30000.0\n",
      "  Utilization: 100.0%\n"
     ]
    }
   ],
   "source": [
    "println(\"\\n=== DIAGNOSTIC INFORMATION ===\")\n",
    "println(\"Objective Value: \", objective_value(model))\n",
    "println(\"Termination Status: \", termination_status(model))\n",
    "\n",
    "# Check fleet utilization\n",
    "total_fleet_used = sum(value(model[:f][ℓ]) * τ[ℓ] for ℓ in L)\n",
    "println(\"\\nFleet Constraint:\")\n",
    "println(\"  Used: $(round(total_fleet_used, digits=1)) / $(T_max)\")\n",
    "println(\"  Utilization: $(round(100*total_fleet_used/T_max, digits=1))%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
